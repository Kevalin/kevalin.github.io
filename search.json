[{"title":"rsync","date":"2023-02-22T15:48:29.000Z","url":"/2023/02/22/rsync/","tags":["Linux"],"content":"rsync是Unix下的一款应用软件，它能同步更新两处计算机的文件与目录，并适当利用差分编码以减少数据传输量。rsync中的一项同类软件不常见的重要特性是每个目标的镜像只需发送一次。rsync可以拷贝／显示目录内容，以及拷贝文件，并可选压缩以及递归拷贝。 服务器端rsync配置 此配置方法只适用于 Centos 7 安装rsync 一般系统都已经安装好了, 这里直接过 配置/etc/rsyncd.conf 配置认证文件/etc/rsync.pass /etc/rsyncd.conf 和 /etc/rsync.pass 的权限一定要设置为 600 rsyncd进程管理 测试同步一般同步有两种情况: 服务端 -&gt; 客户端 分发 客户端 -&gt; 服务端 收集 我们的场景是收集日志, 所以是客户端 -&gt; 服务器的模式 客户端配置安装sersync 配置 举个现在使用的配置例子: 主要需要关注的地方 &lt;localpath&gt;&lt;/localpath&gt; 监控本地目录或文件 &lt;rsync&gt;&lt;/rsync&gt; 同步到远端的rsync服务器 管理sersync服务 如果服务器性能很差, 请使用 -n [Number] 合理降低线程数, /usr/local/sersync2 -r -d -n 2 -o /usr/local/sersync/conf/confxml.xml "},{"title":"Centos7 搭建L2TP+IPsec VPN","date":"2023-02-22T15:27:20.000Z","url":"/2023/02/22/Centos7-%E6%90%AD%E5%BB%BAL2TP-IPsec-VPN/","tags":["Linux","VPN"],"content":"Centos7 搭建L2TP+IPsec VPN L2TP是一种工业标准的Internet隧道协议，功能大致和PPTP协议类似，比如同样可以对网络数据流进行加密。不过也有不同之处，比如PPTP要求网络为IP网络，L2TP要求面向数据包的点对点连接；PPTP使用单一隧道，L2TP使用多隧道；L2TP提供包头压缩、隧道验证，而PPTP不支持。L2TP本身不提供加密功能, 经常搭配IPsec加密协议一起使用, 可以提供比PPTP更高级别的数据加密。 前期准备检查L2TP需要的环境支持 安装需要安装的软件 ppp: 提供用户名密码验证功能，实现 VPN 的用户账号密码验证 (Centos7.x已经自带) libreswan: 提供 IPsec 功能，加密 IP 数据包 xl2tpd: 提供 VPN 功能，依赖于 ppp 和 libreswan 开始安装 配置xl2tpd配置文件/etc/xl2tpd/xl2tpd.conf ppp配置文件/etc/ppp/options.xl2tpd IPsec主配置文件/etc/ipsec.conf :::info 第一行config setup必须左对齐，即前面不能有空格，否则会报错 其他每一行都必须以Tab开头，否则会报错 如果安装的是 openswan，可能需要在 config setup 之前添加 version 2.0::: 在/etc/ipsec.secrets中设置PSK密钥 接着继续配置服务器, 修改配置文件/etc/ipsec.d/l2tp-ipsec.conf :::info conn开头的两行必须左对齐，开头不能有空格，其他每一行必须以Tab缩进 left 此时也要填服务器的外网IP::: 添加账号密码配置文件/etc/ppp/chap-secrets 这里我习惯性的给用户指定固定IP, 方便管理, 如果你是使用*代替, 那就会自动分配指定段的IP地址 开启内核转发配置文件/etc/sysctl.conf 完了, 重载内核配置 配置ip转发 启动 Windows客户端配置 windows+r打开运行，输入services.msc，查找ipsec policy agent，启用服务 打开注册表，路径HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\Rasman\\Parameters 添加DWORD值(32位)值，名称ProhibitIpSec，值为 1 由于缺省的 Windows XP L2TP 传输策略不允许不使用 IPSec 加密的 L2TP 传输，修改AllowL2TPWeakCrypto的值为1 重启电脑 Linux客户端配置 以Centos 7为例 安装 VPN 客户端 配置strongSwan 配置xl2tpd 连接VPN 扩展知识比较一下现在主流VPN协议的优缺点 PPTP点对点隧道协议（英语：Point to Point Tunneling Protocol，缩写为PPTP）是实现虚拟专用网（VPN）的方式之一。PPTP使用传输控制协议（TCP）创建控制通道来发送控制命令，以及利用通用路由封装（GRE）通道来封装点对点协议（PPP）数据包以发送资料。这个协议最早由微软等厂商主导开发，但因为它的加密方式容易被破解，微软已经不再建议使用这个协议。 优点 速度快 几乎所有平台都内置 配置极为简单 缺点 受到美国国安局威胁 不安全 L2TP and L2TP/IPsec优点 可供所有现代的设备及操作系统使用 容易设定 缺点 比OpenVPN慢 可能受到美国国安局的威胁 与限制力强的防火请一起使用会有问题 美国国安局极有可能已经削弱这个协议的能力 OpenVPNOpenVPN是一个用于创建虚拟私人网络加密通道的软件包，最早由James Yonan编写。OpenVPN允许创建的VPN使用公开密钥、电子证书、或者用户名／密码来进行身份验证。 它大量使用了OpenSSL加密库中的SSL/TLS协议函数库。 OpenVPN的技术核心是虚拟网卡，其次是SSL协议实现。 优点 具备能跨越大多数防火墙的能力 高度可配置 因为是开放资源，所以可以轻松修正后门 能使用各种加密功能运算法 高度安全性 缺点 设定起来有点棘手 需要用到第三方软件 桌面电脑支援做得好，可是流动设备的则需要改进 SSTPSSTP可以创建一个在HTTPS上传送的VPN隧道，从而消除与基于PPTP（点对点隧道协议）或L2TP（第2层隧道协议）VPN连接有关的诸多问题。因为这些协议有可能受到某些位于客户端与服务器之间的Web代理、防火墙和网络地址转换（NAT）路由器的阻拦。 这种SSTP只适用于远程访问，不能支持站点与站点之间的VPN隧道。 优点 具备越过大多数防火墙的能力 安全标准取决与密码，但一般来说是安全的 能完全融入Windows操作系统 微软支援 缺点 因为是专利标准是由微软公司持有，因此不能修正后门 只能在Windows平台上操作 IKEv2因特网密钥交换（英语：Internet Key Exchange，简称IKE或IKEv2）是一种网络协议，归属于IPsec协议族，用以创建安全关系（Security association，SA）。它创建在奥克利协议（Oakley protocol）与ISAKMP协议的基础之上。 优点 极度安全–支援各种密码如3DES、 AES、 AES 256等 支援黑莓设备 稳定，特别是在连接中断或者是交换网络使用时更是如此 容易设定，至少从用户终端是如此 比 L2TP、PPTP 及 SSTP相对更快速 缺点 支援平台有限 为基础的方案像是SSTP或OpenVPN而较容易被阻挡，因为使用UDP 端口500 不是开放资源实现方案 在非服务器端施用IKEv2比较棘手，能导致一些潜在问题 参考 第二层隧道协议 CentOS 7搭建L2TP VPN CentOS7 搭建L2TP Centos7 搭建 L2TP+ IPsec VPN L2TP连接尝试失败，因为安全层再初始化与远程计算机的协商时遇到一个处理错误 比较VPN协议: PPTP 对 L2TP 对 OpenVPN 对SSTP 对 IKEv2 Configuring L2TP connection on Centos 7 "},{"title":"ksmd 占用太多 CPU 资源","date":"2023-02-22T15:20:48.000Z","url":"/2023/02/22/ksmd-%E5%8D%A0%E7%94%A8%E5%A4%AA%E5%A4%9A-CPU-%E8%B5%84%E6%BA%90/","tags":["Linux","kvm"],"content":"在一台 Centos 7.5 服务上运行了4台kvm, 发现ksmd的CPU占用时间最大, 占用比一直处于30%-50%左右 ksm是基于内核的虚拟机KVM用来自调优的, 通过调整一些参数使KVM主机获得更好的性能. 通过使用kms, 可以使虚拟机获得更多的内存启动, 简而言之, 可以超过宿主机内存限制, 过度分配内存. 但使用ksm会带来性能损失, 一般情况会损失10%. 在RHEL 6+(Centos 6+)和Fedora 16+中, ksm默认打开. ksm通过ksmd和ksmtuned两个服务实现. 是否要使用ksm 如果系统资源很充裕, 建议关闭 如果系统资源很紧张, 建议开启 关闭ksm 调优ksm/etc/ksmtuned.conf是ksm的配置文件, 我们可以适当的进行一些参数调整, 重启服务 KSM_MONITOR_INTERVAL 表示ksm每次内存扫描的时间 KSM_SLEEP_MSEC 表示每次扫描休息的间隔时间(最小值为10)，KSM扫描会占用一些CPU的开销，所以当KVM虚拟机数量或者应用软件较少时可以调整KSM_SLEEP_MSEC至一个较大的值，反之则设置较小的值;同时当Hypervisor里面的虚拟机的内存调优到达一个稳定状态，也可以根据情况把这个参数调小节省CPU的开销 KSM_THRES_COEF 表示临界值系数 KSM_THRES_CONST 表示临界值常量 KSM_NPAGES_BOOST 表示内存页合并增加数量 KSM_NPAGES_DECAY 表示内存页合并减少数量 KSM_NPAGES_MIN 表示内存页合并最小值 KSM_NPAGES_MAX 表示内存页合并最大值 LOGFILE 表示ksmtuned的日志存放路径，建议使用默认路径 DEBUG 取消注释才生效，建议使用默认值 "},{"title":"在Centos上搭建git服务","date":"2021-03-21T06:17:19.593Z","url":"/2021/03/21/%E6%90%AD%E5%BB%BAgit%E6%9C%8D%E5%8A%A1/","tags":["git","gitolite"],"content":" 安装git在centos系统上安装git 接下来我们 创建一个git用户组和用户，用来运行git服务 安装gitolite使用gitolite对git库进行权限控制 客户端生成密钥 上传你本机的公钥到git服务器git用户的家目录，来为gitolite的管理员授权 在服务器上安装gitolite 注意，进入.ssh目录，如果存在authorized_keys，删除即可。 测试是否执行成功首先git根目录下是否生成了projects.list和repositories同时可以进入.ssh，可以看到新生成的authorized_keys，以后每一次提交新用户都会写到这个里边。判断是否用户添加成功，看这个里边文件是否新增了那个用户的key即可。 客户端clone gitolite-admin来控制权限在客户端修改gitolite的配置文件，然后push到服务器上完成权限更新 在客户端修改gitolite配置gitolite-admin只有2个文件夹，conf/gitolite.conf控制权限配置，keydir目录用来存放所有客户端的公钥 举个栗子 修改完配置之后直接push到远端仓库既可以。如果是新建的空仓库，只需要在配置里面写上名字，push更新之后gitolite会自动在/home/git/repositories目录新建你配置的仓库。访问远程仓库的地址一般是git@yourServer:yourRepoName.git gitolite的详细配置可以参考此处Git-Gitolite"},{"title":"电纸书与电子书","date":"2020-01-04T02:12:12.000Z","url":"/2020/01/04/%E7%94%B5%E7%BA%B8%E4%B9%A6%E4%B8%8E%E7%94%B5%E5%AD%90%E4%B9%A6/","tags":["电子书","电纸书","Kindle","阅读"],"content":"俺是从智能移动设备普及之后才开始接触电子书，大概是2010年的时候，当时入手了一部三星的I9000，主流的安卓手机厂商还是三星、摩托罗拉和HTC，三足鼎立啊！ 当时，俺所接触的电子书大多数是以txt结尾的，在I9000中主力使用的是Anyview这个App，用过塞班系统手机的同学都应该知道这个阅读器吧，界面十分的简洁，操作简单明了，而且没有广告，良心之作啊！目前IOS和安卓都可以很方便的下载安装，这里附上它的官网。 N久之后，俺转投了乔大爷的iPhone，不得不说真香！ … N久之后，又了解到Kindle这个压泡面神器，俺毫不犹豫的入手了。 Kindle俺只使用过2款Kindle产品，一个是目前正在使用的入门级558版，还有一个是Paperwhite 2（卖给了同事）。 啊，为什么俺最终选择了558版的，却没有留下高配的Paperwhite呢？ 强迫症使然。Paperwhite带有的夜间背光功能，虽然可以完美解决夜间阅读的困扰，但是俺实在是受不了它的背光不均匀，哈哈！而558版就不存在这个问题了，因为不发光嘛！可能是心理作用吧，俺觉得558版的屏幕要比Paperwhite的白一些，更加的纯粹一些。 对于ppi不可否认Paperwhite的300秒杀了入门版的167了，字体无毛刺，更加的细腻；还有流畅性Papewhite也是比入门级的强不少。但对于俺来说入门级暂时也够用了，其实习惯了吧。不过有计划换个Kindle oasis 3，25灯背光应该要均衡不少吧，还有色温调节，很赞👍！ 现在Kindle官方固件5.9.6+已经支持自定字体了，该功能也是期待已久。具体方式很简单： 升级 Kindle 固件到 5.9.6 及以上。 使用USB 方式连接Kindle设备到电脑。 打开 Kindle 磁盘，进入目录 fonts ，把字体文件拷贝这里。值得注意的是，目前只支持OTF和TTF这两种字体格式。 安全弹出Kindle设备。 在 Kindle【显示设置】(Aa) 菜单中选择自定义的字体即可。 俺在第一时间升级了此固件，起初使用良好，但不久之后在看书的过程中频繁报错了： 出现错误。如果您从亚马逊购买了此内容，请从设备删除并从云端重新下载。 究其原因你看的是非官方文档（不是正版）。所以大家还是多多支持正版吧！不过俺喜欢无耻白嫖。 对于这个问题，目前亲测的一个解决办法是：打开一个官方文档，然后将字体设置为内置字体，然后重启Kindle设备。后面再也不要使用自定义字体就没事啦！ Calibre既然谈到了Kindle，那就不得不说下PC端的电子书管理软件了Calibre，开源免费多平台有中文，功能强大，几乎可以打开市面的所有电子书格式，甚至可以编辑和互转电子书，作者的更新速度也是非常惊人。 俺一般白嫖的电子书都会先导入Calibre，获取电子书的元数据和封面，然后使用Calibre推送到Kindle设备，也可以连接USB直接Copy到Kindle设备，主要是因为在Calibre鼓捣一番之后导入到Kindle的电子书都是带封面的，哈哈，强迫症患者是无法忍受在Kindle里面的书籍是没有酷酷的封面的😂。 操作界面： 阅读界面： 分享一下俺的一些小设置： 字体：思源宋体。 背景色：rgb(248, 241, 227)，俺定义为“纸黄”。 行间距：这个要到样式里面自定义 页面布局：顶部20，底部20，左边40，右边40。 杂项：勾选了第一条和最后一条。 App这里介绍的App俺只在iOS上测试过，安卓党就不好意思啦！ 前面已经介绍了一款很不错的App——Anyview，这里再补充几个俺在iOS上使用过的App： KyBook2 / KyBook3 / 山丘阅读器这一类App俺的主要关注点是——是否支持mobi和azw3，即使俺不使用Kindle阅读器也要坚持格式是这样的✊。上面3款都支持主流的电子书格式，包括txt、epub、mobi、azw3等等。 KyBook系列有内部付费可以解锁更佳完整的强大功能，但是基础版也够用了！但是有广告。 山丘阅读器是俺目前在手机上使用最多的电子书App了，功能虽没有KyBook强大，但也是完全够用的，最重要的是没有广告哦，也没有付费项，好评😍。 微信读书 / 网易蜗牛读书这一类算一种社交型电子书App了，界面精美，有书评、有笔记共享、有排名等等，会员制。 微信读书依托微信大流量就不用说了，可以互看微信好友的阅读书籍、每周排名、好友分享的阅读点评，等等。最重要的是无限卡送的真猛，俺都是免费无限阅读的。 网易蜗牛读书是另一种方式，每天都可以免费无限制阅读1小时/2小时(点广告后)，如果你每天只想阅读1-2小时，这个应该很适合你。资源比起微信读书要少一点。 因为可以白嫖会员，俺选择了微信读书😁。 电子书资源俺的资源来源主要是Telegram群组。这里就推荐两个常用的： zread (推) - 什么书值得读：有推送服务，绑定自己的Kindle邮箱后可以直接推送到Kindle设备，非常方便，下载有次数限制（每天只能下载一本书的资源），书籍推荐推送比较频繁。 每周一书：直接提供电子书的下载文件，没有下载限制，书籍推荐推送很慢，看名字就知道啦！ 这两个群组推荐的书籍基本上会涵盖3个主流格式（epub/mobi/azw3），有的会有txt和pdf文件。 怎么使用TG这里就不赘述啦，大家自行谷歌吧！额，你都可以谷歌了😓…"},{"title":"谈谈MySQL中的utf8和utf8mb4","date":"2019-12-26T06:08:38.000Z","url":"/2019/12/26/%E8%B0%88%E8%B0%88MySQL%E4%B8%AD%E7%9A%84utf8%E5%92%8Cutf8mb4/","tags":["MySQL","字符集","character"],"content":"UTF-8使用一至六个字节为每个字符编码（尽管如此，2003年11月UTF-8被RFC 3629重新规范，只能使用原来Unicode定义的区域，U+0000到U+10FFFF，也就是说最多四个字节）。然而在MySQL的utf8编码的每个符号最多三个字节，所以它的别名也叫utf8mb3，它支持的范围只有U+000000到U+00FFFF，当我们存入一个正常UTF-8编码的字符但有超过MySQL的utf8字符编码范围的内容时就会有问题了，例如Emoji表情。 我们要清楚的知道，MySQL的utf8是不能等同于我们一般认为的UTF-8的，它不能提供完整的Unicode支持，所以是有可能导致数据丢失或安全性问题。 MySQL在5.5.3之后提供了一个新的编码方式──utf8mb4，它支持正常的UTF-8和完整的Unicode，甚至是星座符号，例如♈，哈哈，是不是强大了不少。因此，我们在使用MySQL时，最好使用utf8mb4这个编码方式。 查看当前MySQL字符集 上面展示的参数还是很多的，它们是什么意思，相互之间又有什么关系呢？ MySQL有两个字符集概念：一个就是字符集本身（character开头的），一个是字符集校验规则（collation开头的）。字符集影响数据在传输和存储过程中的处理方式，而字符集校验则影响ORDER BY和GROUP BY这些排序方式。 character_set_client客户端使用的字符集，相当于网页中的字符集设置 character_set_connection 连接数据库的字符集设置类型，如果代码中没有指明连接数据库使用的字符集类型就按照服务器端默认的字符设置 character_set_database数据库服务器中某个库使用的字符集设定，如果建库时没有指明，将使用服务器安装时指定的字符集设置 character_set_filesystem文件系统格式 character_set_results数据库给客户端返回时使用的字符集设定，如果没有指明，使用服务器默认的字符集 character_set_server服务器安装时指定的默认字符集设定 character_set_system数据库系统使用的字符集设定 collation_connection连接字符集的校对规则 collation_database 默认数据库使用的校对规则。当默认数据库改变时服务器则设置该变量。如果没有默认数据库，变量的值同collation_server collation_server服务器的默认校对规则 如果你的数据库还不是5.5.3+版本，请先升级你的MySQL。当然升级前备份一下你的数据库啦，以防万一。 修改databases，tables和columns字符集的方法 还有一点要注意的是utf8mb4是向下兼容utf8的，所以也不用担心改变字符集导致数据丢失的问题。 修改连接，客户端和服务器字符集在代码中可以通过简单的SET NAMES utf8mb4来完成更换。当使用SET NAMES utf8mb4时，其实就是执行了下面三句： 而服务器的字符集一般是在启动配置/etc/my.cnf中配置的，例如： 总而言之，从现在开始，我们 尽量在MySQL中使用utf8mb4而不要再使用utf8啦！！！ 参考 What is the difference between utf8mb4 and utf8 charsets in MySQL? How to support full Unicode in MySQL databases MySQL字符集设定总结 再见乱码：5分钟读懂MySQL字符集设置 set names 都做了什么 "},{"title":"Stack vs Heap","date":"2019-11-13T06:52:21.000Z","url":"/2019/11/13/Stack-vs-Heap/","tags":["C","Memory"],"content":"The Stack什么是堆栈？它是计算机内存中的一个特殊区域，存储着被函数（包括main()函数）创建的临时变量。它由CPU非常紧密的管理和优化，是一种LIFO（后进先出）的数据结构。函数每一次定义一个新的变量，它都会被放进堆栈中。当函数执行完成退出时，被这个函数放到堆栈里的变量都会被释放，也就是从堆栈中被删除。一旦堆栈变量被释放，对于其他的堆栈变量而言，这个特殊的内存区域就变的可用。 使用堆栈来存储变量的好处是内存是由系统来管理，你不必手动的分配和释放内存。更重要的是，CPU管理堆栈内存非常的高效，从里面读写变量都是非常快速的。 对于堆栈还有一个要注意的地方，堆栈是有小大限制的，并且随着底层操作系统的不同，这个大小也是不同的。 总结一下： 堆栈占用的大小会随着函数push和pop局部变量而增加和减小 堆栈内存不需要自己手动管理，它的分配和释放都是自动 堆栈有大小限制 堆栈变量仅在创建它们的函数运行时存在 The Heap堆是计算机内存中不会自动为您管理的区域，并且不受CPU严格管理。它是内存中更自由浮动的区域（并且更大）。要在堆上分配内存，必须使用内置的C函数malloc()或calloc()。在堆上分配内存后，一旦不再需要，要使用free()释放该内存。如果不这样做，程序将发生所谓的内存泄漏，也就是说，堆上的内存仍将被保留（并且其他进程将无法使用）。 与堆栈不同，堆对变量大小没有限制（除了计算机物理内存限制以外）。相比于堆栈，堆内存的读写要稍慢一些，因为必须使用指针来访问堆上的内存数据。 还有一点和堆栈不同的是，在堆上创建的变量可以在程序中任何位置的任何函数访问。堆变量本质上是全局的。 利弊之分Stack 非常快的访问速度 不必显示的取消分配的变量 内存空间由CPU高效的管理，因而不会变的碎片化 只能局部变量 变量不能调整大小 Heap 变量可以被全局访问 没有内存大小的限制 访问速度相对于堆栈要慢一些 无法保证有效利用空间，随着时间的推移，内存块可能会随着内存块的分配而碎片化，然后释放 必须手动的管理内存（分配和释放） 变量可以使用realloc()调整大小 如何使用？什么时候应该使用堆，什么时候应该使用堆栈？ 如果您需要分配一个大的内存块（例如，一个大array或一个大的struct），并且需要长时间保持该变量（例如全局变量），则应该在堆上分配它。如果您要处理的变量相对较小，并且只要使用它们的函数时使用，那么您应该使用堆栈，它更容易，更快捷。如果您需要像数组和结构这样的变量可以动态更改大小（例如，可以根据需要增加或缩小的数组），则可能需要在堆上分配它们，并使用动态内存分配函数，如malloc()，calloc() ，realloc()和free()来“手动“管理该内存。"},{"title":"React.js小书笔记","date":"2019-11-04T03:41:30.000Z","url":"/2019/11/04/React-js%E5%B0%8F%E4%B9%A6%E7%AC%94%E8%AE%B0/","tags":["前端","React.js"],"content":"第一阶段一个组件应该有自己的显示形态行为，组件的显示形态和行为可以由数据状态（state）和配置参数（props）共同决定。数据状态和配置参数的改变都会影响到这个组件的显示形态。 React.js基本环境React.js基本上无法单独使用，不管是在开发阶段还是生产阶段都需要一堆工具和库辅助。 一般我们说的React.js全家桶： Babel 编译阶段 Redux 状态管理工具 React-router 编写单页应用必备 使用官方推荐的工具create-react-app创建工程 启动之后会自动打开浏览器看到一个简单的页面了。 JSX一个 DOM 元素包含的信息其实只有三个：标签名，属性，子元素。 JSX 在编译的时候会变成相应的 JavaScript 对象描述。所谓的JSX其实就是JavaScript对象。 从 JSX 到页面到底经过了什么样的过程： 需要中间这个JavaScript对象结构的原因： 方便不同的render库渲染到不同的终端。例如：React-canvas渲染到canvas，ReactNative之类。 当数据变化，需要更新组件的时候，就可以用比较快的算法操作这个 JavaScript 对象，而不用直接操作页面上的 DOM，这样可以尽量少的减少浏览器重排，极大地优化性能。 简单总结一下，要记住几个点： JSX 是 JavaScript 语言的一种语法扩展，长得像 HTML，但并不是 HTML。 React.js 可以用 JSX 来描述你的组件长什么样的。 JSX 在编译的时候会变成相应的 JavaScript 对象描述。 react-dom 负责把这个用来描述 UI 信息的 JavaScript 对象变成 DOM 元素，并且渲染到页面上。 组件的render方法在React.js中一切皆组件。在编写React.js组件时，一般要继承React.js的component。 一个组件类必须实现一个render方法，这个render方法必须要返回一个 JSX 元素（必须要用一个外层 JSX 元素把所有内容包裹起来）。 在 JSX 中插入 JavaScript 表达式，使用 &#123;&#125; 包裹，&#123;&#125; 中可以放任何 JavaScript 代码，包括变量、表达式计算、函数执行等等。标签和标签的属性上都可以使用表达式。 表达式的值为null时，React.js 会什么都不显示，相当于忽略了该表达式。所以可以使用这个来显示和隐藏某些元素。 组件的state和setStatestate 用来存放组件的状态。 setState 方法可以接受一个对象参数来改变 state 中的状态。当我们调用这个函数的时候，React.js 会更新组件的状态 state ，并且重新调用 render 方法，然后再把 render 方法所渲染的最新的内容显示到页面上。 当你调用 setState 时，React.js并不会马上更新 state 中的值，只是将要更新的值缓存起来，稍后才更新。所以当我们 setState 之后，立马使用新的 state 值是无效的。 如何解决这个问题呢？setState 还可以接受一个函数参数。React.js 会把上一个 setState 的结果传入这个函数，你就可以使用该结果进行运算、操作，然后返回一个对象作为更新 state 的对象： 这样就可以达到上述的利用上一次 setState 结果进行运算的效果。 组件的propsprops 可以让组件具有一定的“可配置”性。每个组件都可以接受一个 props 参数，它是一个对象，包含了所有你对这个组件的配置，一旦传入就无法改变。 props的获取组件内部通过 this.props 的方式获取组件的参数。 props的传递在使用一个组件时，可以把参数放在属性标签中，所有的属性都会作为 props 对象的键值。 前面的章节我们说过，JSX 的表达式插入可以在标签属性上使用。所以其实可以把任何类型的数据作为组件的参数，包括字符串、数字、对象、数组、甚至是函数等等。 defaultProps顾名思义默认参数配置。 总结 为了使得组件的可定制性更强，在使用组件的时候，可以在标签上加属性来传入配置参数。 组件可以在内部通过 this.props 获取到配置参数，组件可以根据 props 的不同来确定自己的显示形态，达到可配置的效果。 可以通过给组件添加类属性 defaultProps 来配置默认参数。 props 一旦传入，你就不可以在组件内部对它进行修改。但是你可以通过父组件主动重新渲染的方式来传入新的 props，从而达到更新的效果。 state vs propsstate 的主要作用是用于组件保存、控制、修改自己的可变状态。state 在组件内部初始化，可被组件自身修改，而外部不能访问也不能修改。你可以认为 state 是一个局部的、只能组件被自身控制的数据源。state 中的状态可以被 this.setState 方法进行更，并导致组件重新渲染。 props 的主要作用是让该组件的父组件可以传入参数来配置改组件。它是外部传入进来的配置参数，组件内部无法控制和修改它。因此，除非外部组件传入新的 props，否则组件此时的 props 永远保持不变。 state 和 props 有着千丝万缕的关系。它们都可以决定组件的行为和显示形态。一个组件的 state 中的数据可以通过 props 传给子组件，一个组件可以使用外部传入的 props 来初始化自己的 state。但是它们的职责其实非常明晰分明：**state 是让组件控制自己的状态，props 是让外部对组件自己进行配置**。 只要涉及到状态，总是会带来软件设计的复杂性。一个简单规则：尽量少用 state，多用 props。没有 state 的组件叫做无状态组件，React.js 非常鼓励无状态组件。因为状态会带来管理的复杂性，我们尽量多地写无状态组件，尽量少地写有状态的组件。这样会降低代码维护的难度，也会在一定程度上增强组件的可复用性。 第二阶段状态提升当某个状态被多个组件依赖或者影响的时候，就把该状态提升到这些组件的最近公共父组件中去管理，用 props 传递数据或者函数来管理这种依赖或着影响的行为。 组件的生命周期挂载阶段我们把 React.js 将组件的渲染，并构造 DOM 元素并塞入页面的过程称为组件的挂载。React.js 内部对每个组件都有这样的一个过程： 更新阶段更新阶段的组件生命周期： shouldComponentUpdate(nextProps, nextState): 你可以通过这个方法控制组件是否重新渲染。如果返回 false 组件就不会重新渲染。这个生命周期在 React.js 性能优化上非常有用。 componentWillReceiveProps(nextProps)：组件从父组件接收到新的 props 之前调用。 componentWillUpdate()：组件开始重新渲染之前调用。 componentDidUpdate()：组件重新渲染并且把更改变更到真实的 DOM 以后调用。 参考： Virtual-DOM 策略 更新阶段的生命周期官方文档 React.js中的DOM操作其实在 React.js 中基本不需要和 DOM 直接打交到。而在 React.js 当中可以直接通过 setState 的方式重新渲染组件，渲染的时候可以把新的 props 传递给子组件，从而达到页面更新的效果。 但是有些时候 React.js 并不能满足所有 DOM 操作需求，我们可以使用 React.js 提供的 ref 属性从 HTML 标签上（其实组件标签也可以）获取一家挂载的 DOM 节点，进而来进行 DOM 操作。 但是记住一个原则：能不使用ref就不用。多余的 DOM 操作其实是代码里面的“噪音”，不利于我们理解和维护。 props.children 和容器类组件容器类组件就像是一个空盒子，我们可以放任意的东西到里面。所有嵌套在这个容器组件中的 JSX 结构都可以在组件内部通过 props.children 获取到： 把 props.children 获取到的内容打印出来其实是一个数组结构，我们使用起来也会更加的灵活。 使用自定义组件的时候，可以在其中嵌套 JSX 结构。嵌套的结构在组件内部都可以通过 props.children 获取到，这种组件编写方式在编写容器类型的组件当中非常有用。而在实际的 React.js 项目当中，我们几乎每天都需要用这种方式来编写组件。 dangerouslySetInnerHTML 和 style 属性dangerouslySetInnerHTML出于安全的考虑（XSS攻击），在 React.js 中所有的表达式插入的内容都会被自动转义，就相当于 jQurey 里面的 text(...) 函数一样，任何 HTML 格式都会被转移掉。为此，React.js提供了一个属性dangerouslySetInnerHTML，可以让我们动态的设置元素的 innerHTML： 要注意这个__html 属性值就相当于元素的 innerHTML，这样我们就可以动态的渲染元素的innerHTML结构了。 这里或许有些朋友会觉得很奇怪，为什么 React.js 要把这个搞的这么复杂，其实这个是 React.js团队有意为之，React.js 团队认为把事情搞复杂可以防止（警示）大家滥用这个属性。 styleReact.js 中的元素style属性用法和 DOM 中的不太一样： 需要把 CSS 属性变成一个对象再传给元素 CSS 属性对象里面的 key 值必须是对应的驼峰命名, font-size换成fontSize，text-align换成textAlign 使用对象作为style方便我们使用props或者state中的数据结合setState来修改样式，非常灵活: 然后只要简单的setState(&#123;color: &#39;blue&#39;&#125;)就可以很方便的修改元素的颜色为蓝色。 PropsTypes 和组件参数验证React.js 提供的 PropTypes 提供了一系列的数据类型可以用来配置组件的参数： 首先要引入这个库 import PropsType from &#39;prop-types&#39;,然后在定义组件类时设置一个静态方法对象propTypes既可以完成 props 参数类型验证了，很方便吧！ 通过 PropTypes 给组件的参数做类型限制，可以在帮助我们迅速定位错误，这在构建大型应用程序的时候特别有用；另外，给组件加上propTypes，也让组件的开发、使用更加规范清晰。 这里建议大家写组件的时候尽量都写propTypes，有时候有点麻烦，但是是值得的。 待续 Reduce…"},{"title":"Mac下Beyond Compare无限试用","date":"2019-10-29T07:45:07.000Z","url":"/2019/10/29/Mac%E4%B8%8BBeyond-Compare%E6%97%A0%E9%99%90%E8%AF%95%E7%94%A8/","tags":["Mac","软件"],"content":"Mac升级到Catalina之后发现老版的Beyond Compare无法使用了，没办法，去官网下载了最新的4.3.x安装后终于可以使用啦！不料试用期到期后又悲催了。网路上找了很多的破解版本/破解教程都不行，只能另辟蹊径了——无限试用！ 具体操作方法打开命令行终端，进入到程序的安装目录： 修改可执行文件BCompare为BCompare.real，并创建脚本 vim BCompare之后就进入vim编辑器界面了，在英文输入状态下键盘输入i进入编辑模式，复制粘贴下面的内容到编辑器里面 然后，键盘输入esc，退出编辑模式，然后英文输入状态输入:wq，保存退出。 最后，我们修改可执行文件的权限： 再次打开软件，奇迹出现了！"},{"title":"microtasks and macrotasks","date":"2019-07-03T07:39:38.000Z","url":"/2019/07/03/microtasks-and-macrotasks/","tags":["Node.js","eventloop"],"content":"在event loop中经常会提到2个task queue，一个是microtasks，另一个是macrotasks，它们之间有什么不同呢？ 每一次事件循环，都会先执行macrotask queue的任务，此queue在[ WHATWG specification]中被简单的叫做task queue。当这个macrotask被执行完之后，就会执行这个事件循环中的所有可以执行microtasks。在处理这些microtasks时，他们可以排队更多microtasks，这些microtasks都将逐个运行，直到microtasks队列耗尽。 What are the practical consequences of this?如果一个microtask中递归了其他的microtasks，可能会花费很长的时间才会去执行macrotask。这意味着，你可能会终止一些UI操作，或者是完成了I/O操作之后不在处理别的任务。 在Node.js中，process.nextTick（属于microtasks）提供了一个内部保护机制process.maxTickDepth来防止出现这样的阻塞。process.maxTickDepth的默认值是1000，当达到这个限制值时就会停止执行下面的microtasks，而来继续执行下面的macrotask。 So when to use what?一般情况下，当你要在同步中使用异步操作时会用microtasks，也就说是要在执行完同步代码后，在最近的将来就执行这个异步任务。其他的情况，就请使用macrotasks吧。 Examplesmacrotasks setTimeout setInterval setImmediate requestAnimationFrame I/O UI rendering microtasks process.nextTick Promises Object.observe MutationObserver 参考文件 stackoverflow "},{"title":"tcp retransmission","date":"2017-06-24T03:45:35.000Z","url":"/2017/06/24/tcp-retransmission/","tags":["网络"],"content":" 为什么tcp会存在retransmission？tcp协议是一个可靠的协议。它通过重新发送(retransmission)来实现tcp片段传输的可靠性。简单来说，tcp会不断重复发送tcp片段，知道片段被正确接收。 超时重新发送当发送方送出一个TCP片段后，将开始计时，等待该TCP片段的ACK回复。如果接收方正确接收到符合次序的片段，接收方会利用ACK片段回复发送方。发送方得到ACK回复后，继续移动窗口，发送接下来的TCP片段。如果直到计时完成，发送方还是没有收到ACK回复，那么发送方推断之前发送的TCP片段丢失，因此重新发送之前的TCP片段。这个计时等待的时间叫做重新发送超时时间(RTO, retransmission timeout)。 发送方应该在等待多长时间之后重新发送呢？这是重新发送的核心问题。上述过程实际上有往返两个方向： 发送片段从发送方到接收方的传输。 ACK片段从接收方到发送方的传输。整个过程实际耗费的时间称做往返时间(RTT, round trip time)。 如果RTT是固定的，比如1秒，那么我们可以让RTO等于RTT。但实际上，RTT的上下浮动很大。比如某个时刻，网络中有许多交通，那么RTT就增加。在RTT浮动的情况下，如果我们设置了过小的RTO，那么TCP会等待很短的时间之后重新发送，而实际上之前发送的片段并没有丢失，只是传输速度比较慢而已，这样，网络中就被重复注入TCP片段，从而浪费网络传输资源。另一方面，如果RTO时间过长，那么当TCP片段已经实际丢失的情况下，发送方不能及时重新发送，会造成网络资源的闲置。所以，RTO必须符合当前网络的使用状况。网络状况越好，RTO应该越短；网络状况越差，RTO应该越长。TCP协议通过统计RTT，来决定合理的RTO。发送方可以测量每一次TCP传输的RTT (从发送出数据片段开始，到接收到ACK片段为止)，这样的每次测量得到的往返时间，叫做采样RTT(srtt, sampling round trip time)。建立连接之后，每次的srtt作为采样样本，计算平均值(mean)和标准差(standard deviation)，并让RTO等于srtt平均值加上四倍的srtt标准差。 $RTO = mean + 4 std$ (上述算法有多个变种，根据平台不同有所变化) 平均值反映了平均意义上的RTT，平均往返时间越大，RTO越大。另一方面，标准差越大也会影响RTO。标准差代表了RTT样本的离散程度。如果RTT上下剧烈浮动，标准差比较大。RTT浮动大，说明当前网络状况相对不稳定。因此要设置更长的RTO，以应对不稳定的网络状况。 快速重新发送发送方送出一个TCP片段，然后开始等待并计时，如果RTO时间之后还没有收到ACK回复，发送方则重新发送。TCP协议有可能在计时完成之前启动重新发送，也就是利用快速重新发送(fast-retransmission)。快速发送机制如果被启动，将打断计时器的等待，直接重新发送TCP片段。 由于IP包的传输是无序的，所以接收方有可能先收到后发出的片段，也就是乱序(out-of-order)片段。乱序片段的序号并不等于最近发出的ACK回复号。已接收的文本流和乱序片段之间将出现空洞(hole)，也就是等待接收的空位。比如已经接收了正常片段5,6,7，此时又接收乱序片段9。这时片段8依然空缺，片段8的位置就是一个空洞。 TCP协议规定，当接收方收到乱序片段的时候，需要重复发送ACK。比如接收到乱序片段9的时候，接收方需要回复ACK。回复号为8 (7+1)。此后接收方如果继续收到乱序片段(序号不是8的片段)，将再次重复发送ACK=8。当发送方收到3个ACK=8的回复时，发送方推断片段8丢失。即使此时片段8的计时器还没有超时，发送方会打断计时，直接重新发送片段8，这就是快速重新发送机制(fast-retransmission)。 快速重新发送机制利用重复的ACK来提示空洞的存在。当重复次数达到阈值时，认为空洞对应的片段在网络中丢失。快速重新发送机制提高了检测丢失片段的效率，往往可以在超时之前探测到丢失片段，并重复发送丢失的片段。 linux中的RTOLinux中参考RFC-2988来计算RTO，算法核心公式： 这里说的是RHEL5.4的2.6.18内核，RFC-2988实现参考net/ipv4/tcp_input.c中的tcp_rtt_estimator和tcp_set_rto。可以看到，在Linux中alpha=1/8，RTO最小为TCP_RTO_MIN。因为我们的系统中RTT总是很小，所以RTO取值总是能够取到TCP_RTO_MIN。 在看看TCP_RTO_MIN在Linux中的定义： 这里简单的介绍介绍一下HZ，HZ可以理解为1s，所以120*HZ就是120秒，HZ/5就是200ms。详细的：HZ表示CPU一秒种发出多少次时间中断–IRQ-0，Linux中通常用HZ来做时间片的计算，参考 linux中可以配置重传参数 TCP尝试了3次（tcp_retries1默认3）重传后，还没有收到ACK的话，则后续每次重传都需要network layer先更新路由。 TCP默认最多做15次重传。根据RTO(retransmission timeout)不同，最后一次重传间隔大概是13到30分钟左右。如果15次重传都做完了，TCP/IP就会告诉应用层说：“搞不定了，包怎么都传不过去！” 总结TCP协议利用重新发送(retransmission)来实现TCP传输的可靠性。重新发送的基本形式是超时重新发送，根据统计的往返时间来设置超时标准；如果超时，则重新发送TCP片段。另一方面，快速重新发送则通过乱序片段的ACK来更早的推断出片段的丢失。 参考资料   "},{"title":"对Node.js eventloop的理解","date":"2017-03-14T11:09:00.000Z","url":"/2017/03/14/%E5%AF%B9Node-js-eventloop%E7%9A%84%E8%AE%A4%E8%AF%86/","tags":["node.js"],"content":"Node.js的结构 对Node.js的理解 V8 engine是将javascript代码编程成机器语言给计算机执行，类似于一个编译器。 event loop和异步I/O是使用libuv来实现（libuv是用来处理跨平台的event loop和异步I/O的）。对于不同操作系统在异步I/O的处理上存在一点区别，以Linux系统为例，network类异步I/O是用epoll解决，file类异步I/O是采用自建线程池解决（默认4个线程）；Windows是采用IOCP，内部也是线程池来处理异步I/O。 Node.js主程序只运行在一个进程上，执行一个一个任务，如果有异步I/O操作，就分配给线程池处理，然后继续执行主进程下面的任务，异步I/O执行完毕之后，又回到主进程执行对应的回调。 libuv有的功能： Full-featured event loop backed by epoll, kqueue, IOCP, event ports. Asynchronous TCP and UDP sockets Asynchronous DNS resolution Asynchronous file and file system operations File system events ANSI escape code controlled TTY IPC with socket sharing, using Unix domain sockets or named pipes (Windows) Child processes Thread pool Signal handling High resolution clock Threading and synchronization primitives 问题：因为是进程池进行处理，所以会不会出现进程池被占满的情况呢？如果出现这样的情况，Node.js会发生什么？ 对event loop的理解官方介绍上的图： 这里涉及了所有event loop中存在的情况，官方解释： timers: this phase executes callbacks scheduled by setTimeout() and setInterval(). I/O callbacks: executes almost all callbacks with the exception of close callbacks, the ones scheduled by timers, and setImmediate(). idle, prepare: only used internally. poll: retrieve new I/O events; node will block here when appropriate. check: setImmediate() callbacks are invoked here. close callbacks: e.g. socket.on(‘close’, …). 似乎不怎么好理解（年纪大了，个人理解能力有限），还好有另一种解释，将各种情况分成了2类： microtasks： process.nextTick promise Object.observe macrotasks/tasks： setTimeout setInterval setImmediate I/O 它们之间有执行先后顺序。在一个cycle中，当stack空了之后，先执行microtasks，miscrotasks空了之后再执行macrotasks。 有个更清晰的图： 结合上面的图来解读一下下面的代码： 执行结果： 问题：在官方介绍中提到setTimeout(fn, 0)和setImmediate(fn)这2个在一个cycle中的时候，一定是setImmediate要先执行，但在实际测试中发现不一定，囧(/ □ )，难道我写的代码有问题，还是Node版本太旧？ 个人理解不代表官方，理解有问题的地方欢迎大家随时联系指出。 参考文档 官方event loop说明 risingstack博客 libuv官方文档 朴大《深入浅出Nodejs》 "},{"title":"使用node.js开发proxy程序","date":"2017-01-11T15:02:53.000Z","url":"/2017/01/11/%E4%BD%BF%E7%94%A8node-js%E5%BC%80%E5%8F%91proxy%E7%A8%8B%E5%BA%8F/","tags":["node.js"],"content":"这是一个工作中的遗留问题。 对_http_client.js、_http_server.js、stream.js源码的简单研究 之前使用node.js写了一个proxy程序，完成http请求的转发任务，在生产环境中一直存在hang up的问题，proxy大概的工作原理如下： 大致流程如下: client发送请求到proxy proxy收到请求后pipe到site site收到proxy的请求处理之后返回给proxy proxy将结果pipe给client，完成代理工作 核心点分析： req是一个http.inComingMessage可读流实例 preq是通过http.ClientRequest类得到的一个可写流实例 pres其实是preq.on(‘response’)得到的一个http.inComingMessage的可读流实例 res是一个http.ServerResponse的可写流实例 问题：如果client发送请求到proxy，proxy发送请求到site，site还没有来得及response给client的时候，如果client.abort()（也就是client到proxy的socket已经close），proxy会如何处理？ 答：此时proxy还是会正常处理site的返回，但是再将site的返回 pipe到client的时候发现socket已经close，这个时候会触发req的aborted事件，监控到req的aborted事件之后应该close掉proxy到site的socket，这样处理之后会更好的释放socket连接，节省系统资源。还有一个要点就是流的pipe结束会自动结束socket连接（详情可以查看stream.js的源码）。 涉及到的源码如下："},{"title":"SIGTERM vs. SIGKILL","date":"2016-08-07T11:52:04.000Z","url":"/2016/08/07/SIGTERM-vs-SIGKILL/","tags":["linux","操作系统"],"content":"在Unix系统中使用kill命令给进程发送信号对于大多数系统管理员来说不是什么新鲜事，但是对于kill和kill -9有什么不同，我还是被询问过很多次。 在任何时候，你在一个进程上使用kill命令，实际上是你发送了一个信号给进程。标准的C应用程序有这样一个header file，它包含了一些当进程收到一个特殊信号之后需要干什么的步骤。你可以在你的操作系统上使用man kill查看完整的可使用的信号列表。 让我们来看这样一个命令 它将发送一个叫做SIGTERM的信号进程。 一进程收到这个信号，有几个不同的事情可能要发生： 进程可能立刻停止 进程可能短暂延迟清理完进程资源之后再停止 进程可能仍然保持运行 进程能够决定在它收到一个SIGTERM信号之后它想做什么，而大多数进程会先清理它们使用的资源然后在停止工作，也有些不是这样。进程也有可能被配置成收到SIGTERM后做一些完全不同的事情。如果进程处在一个比较糟糕的状态下，例如等待磁盘I/O，它有可能收到信号后不会执行任何相应的动作。 当给一个进程发送SIGTERM没有反映的时候，大多数系统管理员都会寻求一个更加果断的信号。 -9将会告诉kill命令你想发送#9信号（也就是SIGKILL）。从字面意思就可以看到，这个信号很明显要更加的厉害些。 虽然SIGKILL和SIGTERM被定义在相同的header file中，但是SIGKILL是无法被进程忽略的。事实上，进程还没有意识到SIGKILL，因为SIGKILL是直奔内核的init进程。因此，init将停止进程。进程绝对不会得到任何机会去捕获信号，然后做出响应。 尽管如此，在一些特定的情况下内核也不能成功的停止进程。如果进程正在等待网络或者磁盘I/O，内核不能停止掉进程。僵尸进程和处在不间断睡眠状态的进程也不能被内核停止。需要重新启动来清除系统中的这些进程。"},{"title":"Node.js socket hang up error","date":"2016-08-07T08:51:09.000Z","url":"/2016/08/07/Node-js-socket-hang-up-error/","tags":["node.js"],"content":"报socket hang up错误一般有2种可能，下面通过2个例子来说明： 客户端客户端发送请求给远程服务端，没有及时收到服务端响应（默认超时时间为2分钟），这个时候socket就会结束，并抛出socekt hang up的错误信息，我们应该捕获这个错误并正确的处理它。 服务端/代理客户端发送请求给服务器或者是代理服务器，服务器收到请求开始处理（如果是代理会将请求转发被后端真实的站点服务器）,如果在服务器返回信息之前，客户端决定取消请求或者abort掉请求，这时候服务端也出现socekt hang up的报错，报错信息类似下面的例子，肯定会是从socketCloseListener这个函数抛出错误（下面会贴上源码） 如果客户端是浏览器用户这种情况会经常发生，因为用户随时都有可能在服务器端没有返回前就进行了刷新页面的动作，这样的操作会导致前一个请求在服务器端抛出socket hang up的错误。 由于这个报错是客户端自己的意愿操作导致，并且用户也不希望收到任何的报错信息，所以不需要太刻意的处理这个错误信息，直接忽略即可。如果你是作为代理服务器，捕获到这样的报错最好是不要再将请求转发到后端去，直接处理掉即可。 涉及源码注释也是写的很清楚的哦！！！ "},{"title":"使用nvm管理node版本","date":"2016-04-17T12:50:22.000Z","url":"/2016/04/17/%E4%BD%BF%E7%94%A8nvm%E7%AE%A1%E7%90%86node%E7%89%88%E6%9C%AC/","tags":["node.js","nvm"],"content":"nvm安装传送门 此处需要注意的是：nvm安装完成后需要关闭终端，重新连接终端才可以使用nvm 使用nvm安装nodejs 默认nvm是使用国外镜像下载，非常的慢，这里我们改为国淘宝镜像 如果你不想每次指定环境变量NVM_NODEJS_ORG_MIRROR，那你可以将环境变量加入到.bashrc文件中 nvm常用命令 更多命令请使用nvm --help"},{"title":"web服务器性能测试工具","date":"2016-04-17T12:29:51.000Z","url":"/2016/04/17/web%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/","tags":["测试"],"content":"http_load安装从下载最新版本，解压后进入对应的目录，执行make &amp;&amp; make install，安装完成 使用 参数说明： -r 每秒访问数 -p 并发数 -s 总访问时间，以秒为单位 -f 总访问次数 url.txt格式      上面的意思就是对url.txt文本中的url地址随机每秒钟访问500次，访问5分钟，测试过程中请使用top关注性能。一般是采用r和s，p和f组合进行测试 为什么采用这样的组合进行测试？因为并发p和f组合可以更好的测试web服务器的极限吞吐量（也就是满负荷的处理能力），一般关注的测试结果的fetches/sec值；访问频率r和s组合能更好的对服务器进行长时间的测试，来判断web服务的稳定性和资源的使用情况，一般关注的是测试过程中web服务的CPU和内存使用情况 ab 来自Apache的测试工具，因此安装了Apache就自带了ab测试工具 ab的参数很多，功能比较全面，具体的详细参数可以去度娘和谷歌，一般是这样使用 意思是对 进行50并发一共请求10000次，返回结果我们一般关注的是Requests per second服务器吞吐量，每秒处理请求数 webbench安装从下载解压安装make &amp;&amp; make install 使用 意思是500并发访问30s，测试完成后会返回一个Requests: xxxxxxx susceed，通过这个来看服务器的吞吐量，越大越好"}]